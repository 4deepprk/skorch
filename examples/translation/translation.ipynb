{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Translation using skorch\n",
    "\n",
    "This notebook demonstrates how to port the [sequence-to-sequence tutorial][1].\n",
    "\n",
    "[1]: http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import skorch\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "We use the same data loading routines as the tutorial but for the\n",
    "sake of brevity we will leave it out of the notebook and simply\n",
    "import the code from `data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = data.prepareData('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nous sommes sans defenses .', 'we are defenseless .']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The seq2seq model code itself consists of the encoder and the decoder which we can use 1:1 from the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)        \n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, use_cuda):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=data.MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self, use_cuda):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glue\n",
    "\n",
    "In the original code the encoder and decoder are combined in the training and\n",
    "evaluation code. We refrain from doing this and define a `Seq2Seq`-model that\n",
    "unites both and allows us to have a single point of entry and avoids code\n",
    "duplication for inference and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def params_for(prefix, kwargs):\n",
    "    if not prefix.endswith('__'):\n",
    "        prefix += '__'\n",
    "    return {key[len(prefix):]: val for key, val in kwargs.items()\n",
    "            if key.startswith(prefix)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        encoder, \n",
    "        decoder,\n",
    "        teacher_forcing_ratio=0.5,\n",
    "        hidden_size=256,\n",
    "        max_length=data.MAX_LENGTH,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder(\n",
    "            hidden_size=hidden_size, \n",
    "            **params_for('encoder', kwargs))\n",
    "        self.decoder = decoder(\n",
    "            hidden_size=hidden_size, \n",
    "            **params_for('decoder', kwargs))\n",
    "        self.max_length = max_length\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        # Encode the input x to the thought vector stored in encoder_outputs.\n",
    "        encoder_hidden = self.encoder.initHidden(use_cuda=x.is_cuda)\n",
    "        encoder_outputs = Variable(torch.zeros(self.max_length, self.encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if x.is_cuda else encoder_outputs\n",
    "                \n",
    "        for ei in range(x.size(1)):\n",
    "            encoder_output, encoder_hidden = self.encoder(x[0, ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "        use_teacher_forcing = y is not None and random.random() < self.teacher_forcing_ratio\n",
    "        ys = []\n",
    "                \n",
    "        target_length = self.max_length if y is None else y.size(1)\n",
    "        target_variable = y\n",
    "        \n",
    "        # Decode the thought vector into the target sequence beginning with a \n",
    "        # start-of-sentence (SOS) token.\n",
    "        decoder_input = Variable(torch.LongTensor([[data.SOS_token]]))                                               \n",
    "        decoder_input = decoder_input.cuda() if x.is_cuda else decoder_input                                     \n",
    "        decoder_hidden = encoder_hidden\n",
    "                \n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = self.decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "                ys.append(decoder_output)\n",
    "                decoder_input = target_variable[0, di]  # Teacher forcing\n",
    "\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = self.decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                ni = topi[0][0]\n",
    "\n",
    "                decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "                decoder_input = decoder_input.cuda() if x.is_cuda else decoder_input\n",
    "\n",
    "                ys.append(decoder_output)\n",
    "                if ni == data.EOS_token:\n",
    "                    break\n",
    "                    \n",
    "        return torch.stack(ys, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "After defining the necessary components we can prepare everything for the training itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Some fluff taken 1:1 from the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(data.EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "    \n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping the seq2seq model in skorch\n",
    "\n",
    "Now we can wrap our model into a `skorch.NeuralNet` where we \n",
    "define how our seq2seq model is trained. For this we need only a few things:\n",
    "\n",
    "1. A proper loss\n",
    "2. The training step (data flow in and out of the model)\n",
    "\n",
    "Since we are dealing with variable length sequences produced\n",
    "by the model we also have to deal with those in the evaluation step.\n",
    "We can solve this issue by padding the sequences to a fixed length.\n",
    "\n",
    "Another extra is that the tutorial uses two separate optimizers for\n",
    "the encoder and the decoder. We can implement this as well, even though\n",
    "it does not make a difference with SGD, it might make a difference when\n",
    "using Adam, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer(skorch.NeuralNet):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        *args, \n",
    "        optimizer_encoder=torch.optim.SGD, \n",
    "        optimizer_decoder=torch.optim.SGD,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.optimizer_encoder = optimizer_encoder\n",
    "        self.optimizer_decoder = optimizer_decoder\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def initialize_optimizer(self):\n",
    "        kwargs = self._get_params_for('optimizer_encoder')\n",
    "        self.optimizer_encoder_ = self.optimizer_encoder(self.module_.encoder.parameters(), **kwargs)\n",
    "        kwargs = self._get_params_for('optimizer_decoder')\n",
    "        self.optimizer_decoder_ = self.optimizer_decoder(self.module_.decoder.parameters(), **kwargs)\n",
    "\n",
    "    def train_step(self, Xi, yi):\n",
    "        self.module_.train()\n",
    "        \n",
    "        self.optimizer_encoder_.zero_grad()\n",
    "        self.optimizer_decoder_.zero_grad()\n",
    "\n",
    "        y_pred = self.infer(Xi, yi)\n",
    "        loss = self.get_loss(y_pred, yi, X=Xi, train=True)\n",
    "        loss.backward()\n",
    "        \n",
    "        self.optimizer_encoder_.step()\n",
    "        self.optimizer_decoder_.step()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def infer(self, Xi, yi=None):\n",
    "        Xi = skorch.utils.to_var(Xi, use_cuda=self.use_cuda)\n",
    "        yi = skorch.utils.to_var(yi, use_cuda=self.use_cuda) if yi is not None else None\n",
    "        return self.module_(Xi, yi)\n",
    "    \n",
    "    def get_loss(self, y_pred, y_true, **kwargs):\n",
    "        y_true = y_true[:, :y_pred.size(1)]        \n",
    "        y_pred_flat = y_pred.view(y_pred.size(0) * y_pred.size(1), -1)\n",
    "        y_true_flat = y_true.view(y_true.size(0) * y_true.size(1))\n",
    "        \n",
    "        return super().get_loss(\n",
    "            y_pred_flat,\n",
    "            y_true_flat,\n",
    "            **kwargs)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y_probas = []\n",
    "        for yp in self.forward_iter(X, training=False):\n",
    "            pad = np.zeros((yp.size(0), data.MAX_LENGTH, yp.size(-1)))\n",
    "            pad[:, :yp.size(1)] = skorch.utils.to_numpy(yp)\n",
    "            y_probas.append(pad)\n",
    "        y_proba = np.concatenate(y_probas, 0)\n",
    "        return y_proba\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iters = 75000\n",
    "use_cuda = True\n",
    "training_pairs = [variablesFromPair(random.choice(pairs)) for i in range(n_iters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now instantiate the `Trainer` with the parameters we want to train our model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-193520381e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ef = Trainer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# We extended the trainer to support two optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# but to get the behavior of one optimizer we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "ef = Trainer(\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    \n",
    "    # We extended the trainer to support two optimizers\n",
    "    # but to get the behavior of one optimizer we can \n",
    "    # simply use SGD for both, just like in the tutorial.\n",
    "    optimizer_encoder=torch.optim.SGD,\n",
    "    optimizer_encoder__lr=0.01,\n",
    "    optimizer_decoder=torch.optim.SGD,\n",
    "    optimizer_decoder__lr=0.01,\n",
    "    \n",
    "    module=Seq2Seq,\n",
    "    module__hidden_size=256,\n",
    "\n",
    "    module__encoder=EncoderRNN,\n",
    "    module__encoder__input_size=input_lang.n_words,\n",
    "    \n",
    "    module__decoder=AttnDecoderRNN,\n",
    "    module__decoder__output_size=output_lang.n_words,\n",
    "    module__decoder__dropout_p=0.1,\n",
    "    \n",
    "    # We have no internal validation.\n",
    "    train_split=None,\n",
    "    \n",
    "    # The decoding code is not meant to be batched\n",
    "    # so we have to deal with a batch size of 1 for\n",
    "    # both training and validation/prediction.\n",
    "    iterator_train__batch_size=1,\n",
    "    iterator_valid__batch_size=1,\n",
    "    \n",
    "    # Training takes a long time, add a progress bar\n",
    "    # to see how far in we are.\n",
    "    callbacks=[\n",
    "        ProgressBar(batches_per_epoch=n_iters),\n",
    "    ],\n",
    "    \n",
    "    use_cuda=use_cuda,\n",
    "    max_epochs=1,\n",
    "    cold_start=False,\n",
    ").initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we fit the seq2seq model by calling `.fit` on the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([n[0].data for n in training_pairs])\n",
    "y = np.array([n[1].data for n in training_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d14b438e2b4dee9f703465217de31a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss        dur\n",
      "-------  ------------  ---------\n",
      "      2        \u001b[36m2.2584\u001b[0m  6140.7647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Trainer at 0x7f5dc90684e0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "plt.plot(np.convolve(ef.history[:,'batches',:,'train_loss'][0], np.ones((N,))/N, mode='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_data = X[:10]\n",
    "pred = ef.predict(eval_data)\n",
    "pred_proba = ef.predict_proba(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['je', 'suis', 'fatiguee', 'de', 'faire', 'la', 'file', '.', 'EOS']\n",
      "['i', 'm', 'tired', 'of', 'the', '.', '.', 'EOS', 'SOS', 'SOS']\n",
      "\n",
      "['ils', 'sont', 'tous', 'partis', '.', 'EOS']\n",
      "['they', 're', 'all', 'hungry', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['tu', 'es', 'le', 'seul', 'canadien', 'que', 'je', 'connaisse', '.', 'EOS']\n",
      "['you', 're', 'the', 'one', 'who', 'i', 'am', '.', '.', 'EOS']\n",
      "\n",
      "['tu', 'le', 'fais', 'comme', 'il', 'faut', '.', 'EOS']\n",
      "['you', 're', 'doing', 'it', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['j', 'ai', 'peur', 'qu', 'il', 'pleuve', '.', 'EOS']\n",
      "['i', 'm', 'afraid', 'he', 'will', 'your', '.', 'EOS', 'SOS', 'SOS']\n",
      "\n",
      "['je', 'ne', 'te', 'donnerai', 'pas', 'davantage', 'd', 'argent', '.', 'EOS']\n",
      "['i', 'm', 'not', 'going', 'to', 'be', 'your', '.', '.', 'EOS']\n",
      "\n",
      "['il', 'est', 'trop', 'confiant', '.', 'EOS']\n",
      "['he', 's', 'too', 'old', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['elle', 'est', 'desireuse', 'de', 'visiter', 'l', 'europe', '.', 'EOS']\n",
      "['she', 'is', 'my', 'to', 'the', '.', 'EOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['je', 'suis', 'un', 'simple', 'employe', 'de', 'bureau', '.', 'EOS']\n",
      "['i', 'm', 'a', 'little', 'of', 'my', '.', 'EOS', 'SOS', 'SOS']\n",
      "\n",
      "['il', 'est', 'sur', 'le', 'point', 'd', 'y', 'aller', '.', 'EOS']\n",
      "['he', 's', 'about', 'to', 'go', '.', 'EOS', 'SOS', 'SOS', 'SOS']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (sent_in, sent_out) in zip(eval_data, pred):\n",
    "    print([input_lang.index2word.get(w[0], '???') for w in sent_in])\n",
    "    print([output_lang.index2word[w] for w in sent_out])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_proba.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
