{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Translation using skorch\n",
    "\n",
    "This notebook demonstrates how to use the code from the [sequence-to-sequence tutorial][1] with skorch!\n",
    "\n",
    "[1]: http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "import skorch\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "We use the same data loading routines as the tutorial but for the\n",
    "sake of brevity we will leave it out of the notebook and simply\n",
    "import the code from `data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = data.prepareData('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['je vais etre votre institutrice .', 'i m going to be your teacher .']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The seq2seq model code itself consists of the encoder and the decoder which we can use 1:1 from the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)        \n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, use_cuda):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=data.MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self, use_cuda):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glue\n",
    "\n",
    "In the original code the encoder and decoder are combined in the training and\n",
    "evaluation code. We refrain from doing this and define a `Seq2Seq`-model that\n",
    "unites both and allows us to have a single point of entry and avoids code\n",
    "duplication for inference and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_for(prefix, kwargs):\n",
    "    if not prefix.endswith('__'):\n",
    "        prefix += '__'\n",
    "    return {key[len(prefix):]: val for key, val in kwargs.items()\n",
    "            if key.startswith(prefix)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        encoder, \n",
    "        decoder,\n",
    "        teacher_forcing_ratio=0.5,\n",
    "        hidden_size=256,\n",
    "        max_length=data.MAX_LENGTH,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder(hidden_size=hidden_size, **params_for('encoder', kwargs))\n",
    "        self.decoder = decoder(hidden_size=hidden_size, **params_for('decoder', kwargs))\n",
    "        self.max_length = max_length\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        # Encode the input x to the thought vector stored in encoder_outputs.\n",
    "        encoder_hidden = self.encoder.initHidden(use_cuda=x.is_cuda)\n",
    "        encoder_outputs = Variable(torch.zeros(self.max_length, self.encoder.hidden_size))\n",
    "        encoder_outputs = encoder_outputs.cuda() if x.is_cuda else encoder_outputs\n",
    "                \n",
    "        for ei in range(x.size(1)):\n",
    "            encoder_output, encoder_hidden = self.encoder(x[0, ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "        use_teacher_forcing = y is not None and random.random() < self.teacher_forcing_ratio\n",
    "        ys = []\n",
    "                \n",
    "        target_length = self.max_length if y is None else y.size(1)\n",
    "        target_variable = y\n",
    "        \n",
    "        # Decode the thought vector into the target sequence beginning with a \n",
    "        # start-of-sentence (SOS) token.\n",
    "        decoder_input = Variable(torch.LongTensor([[data.SOS_token]]))                                               \n",
    "        decoder_input = decoder_input.cuda() if x.is_cuda else decoder_input                                     \n",
    "        decoder_hidden = encoder_hidden\n",
    "                \n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = self.decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "                ys.append(decoder_output)\n",
    "                decoder_input = target_variable[0, di]  # Teacher forcing\n",
    "\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = self.decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "                topv, topi = decoder_output.data.topk(1)\n",
    "                ni = topi[0][0]\n",
    "\n",
    "                decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "                decoder_input = decoder_input.cuda() if x.is_cuda else decoder_input\n",
    "\n",
    "                ys.append(decoder_output)\n",
    "                if ni == data.EOS_token:\n",
    "                    break\n",
    "                    \n",
    "        return torch.stack(ys, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "After defining the necessary components we can prepare everything for the training itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Some fluff taken 1:1 from the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(data.EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "    \n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping the seq2seq model in skorch\n",
    "\n",
    "Now we can wrap our model into a `skorch.NeuralNet` where we \n",
    "define how our seq2seq model is trained. For this we need only a few things:\n",
    "\n",
    "1. A proper loss\n",
    "2. The training step (data flow in and out of the model)\n",
    "\n",
    "Since we are dealing with variable length sequences produced\n",
    "by the model we also have to deal with those in the evaluation step,\n",
    "namely `predict` and `predict_proba` where we can solve this issue \n",
    "by returning a sequence that is padded to a fixed length.\n",
    "\n",
    "Another extra is that the tutorial uses two separate optimizers for\n",
    "the encoder and the decoder. We can implement this as well, even though\n",
    "it does not make a difference with SGD, it might make a difference when\n",
    "using Adam, for example. We can evaluate this difference by doing a \n",
    "grid search over the possible optimizer encoders. For this we will\n",
    "need a `score()` function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(skorch.NeuralNet):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        *args, \n",
    "        optimizer_encoder=torch.optim.SGD, \n",
    "        optimizer_decoder=torch.optim.SGD,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.optimizer_encoder = optimizer_encoder\n",
    "        self.optimizer_decoder = optimizer_decoder\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def initialize_optimizer(self):\n",
    "        kwargs = self._get_params_for('optimizer_encoder')\n",
    "        self.optimizer_encoder_ = self.optimizer_encoder(self.module_.encoder.parameters(), **kwargs)\n",
    "        kwargs = self._get_params_for('optimizer_decoder')\n",
    "        self.optimizer_decoder_ = self.optimizer_decoder(self.module_.decoder.parameters(), **kwargs)\n",
    "\n",
    "    def train_step(self, Xi, yi):\n",
    "        self.module_.train()\n",
    "        \n",
    "        self.optimizer_encoder_.zero_grad()\n",
    "        self.optimizer_decoder_.zero_grad()\n",
    "\n",
    "        y_pred = self.infer(Xi, yi)\n",
    "        loss = self.get_loss(y_pred, yi, X=Xi, train=True)\n",
    "        loss.backward()\n",
    "        \n",
    "        self.optimizer_encoder_.step()\n",
    "        self.optimizer_decoder_.step()\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def infer(self, Xi, yi=None):\n",
    "        Xi = skorch.utils.to_var(Xi, use_cuda=self.use_cuda)\n",
    "        yi = skorch.utils.to_var(yi, use_cuda=self.use_cuda) if yi is not None else None\n",
    "        return self.module_(Xi, yi)\n",
    "    \n",
    "    def get_loss(self, y_pred, y_true, **kwargs):\n",
    "        y_true = y_true[:, :y_pred.size(1)]        \n",
    "        y_pred_flat = y_pred.view(y_pred.size(0) * y_pred.size(1), -1)\n",
    "        y_true_flat = y_true.view(y_true.size(0) * y_true.size(1))\n",
    "        \n",
    "        return super().get_loss(\n",
    "            y_pred_flat,\n",
    "            y_true_flat,\n",
    "            **kwargs)\n",
    "    \n",
    "    def _predict(self, X, most_probable=True):\n",
    "        # return either predicted word probabilities or the most probable \n",
    "        # word using argmax.\n",
    "        y_probas = []\n",
    "        for yp in self.forward_iter(X, training=False):\n",
    "            if most_probable:\n",
    "                pad = np.zeros((yp.size(0), data.MAX_LENGTH))\n",
    "                pad[:, :yp.size(1)] = skorch.utils.to_numpy(yp.max(-1)[-1])\n",
    "            else:\n",
    "                pad = np.zeros((yp.size(0), data.MAX_LENGTH, yp.size(-1)))\n",
    "                pad[:, :yp.size(1)] = skorch.utils.to_numpy(yp)\n",
    "            y_probas.append(pad)\n",
    "        y_proba = np.concatenate(y_probas, 0)\n",
    "        return y_proba\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self._predict(X, most_probable=False)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self._predict(X, most_probable=True)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_true = y_pred.copy()\n",
    "        \n",
    "        for i, yi in enumerate(y):\n",
    "            yi = skorch.utils.to_numpy(yi.squeeze())\n",
    "            y_true[:, :len(yi)] = yi\n",
    "        \n",
    "        return sklearn.metrics.accuracy_score(y_true.flatten(), y_pred.flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 75000\n",
    "use_cuda = True\n",
    "training_pairs = [variablesFromPair(random.choice(pairs)) for i in range(n_iters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now instantiate the `Trainer` with the parameters we want to train our model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    \n",
    "    # We extended the trainer to support two optimizers\n",
    "    # but to get the behavior of one optimizer we can \n",
    "    # simply use SGD for both, just like in the tutorial.\n",
    "    optimizer_encoder=torch.optim.SGD,\n",
    "    optimizer_encoder__lr=0.01,\n",
    "    optimizer_decoder=torch.optim.SGD,\n",
    "    optimizer_decoder__lr=0.01,\n",
    "    \n",
    "    module=Seq2Seq,\n",
    "    module__hidden_size=256,\n",
    "\n",
    "    module__encoder=EncoderRNN,\n",
    "    module__encoder__input_size=input_lang.n_words,\n",
    "    \n",
    "    module__decoder=AttnDecoderRNN,\n",
    "    module__decoder__output_size=output_lang.n_words,\n",
    "    module__decoder__dropout_p=0.1,\n",
    "    \n",
    "    # We have no internal validation.\n",
    "    train_split=None,\n",
    "    \n",
    "    # The decoding code is not meant to be batched\n",
    "    # so we have to deal with a batch size of 1 for\n",
    "    # both training and validation/prediction.\n",
    "    iterator_train__batch_size=1,\n",
    "    iterator_valid__batch_size=1,\n",
    "    \n",
    "    # Training takes a long time, add a progress bar\n",
    "    # to see how far in we are.\n",
    "    callbacks=[\n",
    "        skorch.callbacks.ProgressBar(),\n",
    "    ],\n",
    "    \n",
    "    use_cuda=use_cuda,\n",
    "    max_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove this once #118 is merged\n",
    "trainer.initialize();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we fit the seq2seq model by calling `.fit` on the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([n[0].data for n in training_pairs])\n",
    "y = np.array([n[1].data for n in training_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'optimizer_encoder': [torch.optim.SGD, torch.optim.Adam],\n",
    "    'optimizer_decoder': [torch.optim.SGD, torch.optim.Adam],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(trainer, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "Re-initializing module!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd78c5251c444d0da51e1cd135aff2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pdb on\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8d8afecef0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADBlJREFUeJzt3G9snfdZh/Hru4a9CZkYxAmlrckY\nk6qBVqhMhpRqLC+I6CSUVow/E2IbMJmg8mcvkIp4wQYICRCgiRdbFGBikwjTpM1bYSMkQkhBgqHa\nU2iyNYwqZCy4NM2KaCsQjPbmhY+R5fnPsX2OD75zfaToHJ/n53Pup49y+eRnu6kqJEm9vGLSA0iS\nRs+4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqaN+kXvjgwYN15MiRSb28JO1JCwsL\nt6pqarN1E4v7kSNHmJ+fn9TLS9KelOSLw6xzW0aSGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lq\nyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1\nZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0NFfck15NcTnIpyfwG\n674ryUtJ3jq6ESVJW7VvC2uPV9Wt9Q4muQP4TeAvdjyVJGlHRrkt87PAx4CbI3xOSdI2DBv3As4n\nWUgyu/pgkruAh4HToxxOkrQ9w27LHKuqxSSHgAtJrlbVxRXH3wc8WlUvJVn3SQZfGGYBpqentzuz\nJGkTQ71zr6rFwe1NYA44umrJDPCRJNeBtwLvT/LQGs9zpqpmqmpmampqR4NLkta36Tv3JPuBV1TV\nC4P7J4BfXbmmql6zYv0fAX9WVZ8Y8aySpCENsy1zGJgbbLfsA85W1bkkpwCqyn12Sfp/ZtO4V9U1\n4L41Hl8z6lX1zp2PJUnaCX9DVZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy\n7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Z\nd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJamhoeKe5HqSy0kuJZlf4/jJJE8sH0/ywOhHlSQN\na98W1h6vqlvrHPtL4LGqqiRvAD4K3Lvj6SRJ27KVuK+rql5c8eF+oEbxvJKk7Rl2z72A80kWksyu\ntSDJw0muAp8CfmJUA0qStm7YuB+rqvuBB4FHkrxp9YKqmquqe4GHgF9b60mSzA725OefffbZbQ8t\nSdrYUHGvqsXB7U1gDji6wdqLwGuTHFzj2JmqmqmqmampqW2OLEnazKZxT7I/yYHl+8AJ4MqqNd+a\nJIP79wOvBL48+nElScMY5huqh4G5Qbv3AWer6lySUwBVdRr4AeDtSb4C/Cfww1XlN1UlaUIyqQbP\nzMzU/PxX/ci8JGkDSRaqamazdf6GqiQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7\nJDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zd\nkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JD+4ZZlOQ68ALwEvA/VTWz6viPAo8OPnwR\n+Omq+vsRzvl/fuVPP8fnF58fx1NL0q54/Te9ivd8/7eN9TWGivvA8aq6tc6xfwK+p6r+LcmDwBng\njTueTpK0LVuJ+7qq6m9WfPgZ4O5RPO9axv3VTpI6GHbPvYDzSRaSzG6y9ieBP9/ZWJKknRj2nfux\nqlpMcgi4kORqVV1cvSjJcZbi/sBaTzL4wjALMD09vc2RJUmbGeqde1UtDm5vAnPA0dVrkrwB+APg\nZFV9eZ3nOVNVM1U1MzU1tf2pJUkb2jTuSfYnObB8HzgBXFm1Zhr4OPBjVfWFcQwqSRreMNsyh4G5\nJMvrz1bVuSSnAKrqNPDLwDcA7x+s+6ofl5Qk7Z5N415V14D71nj89Ir77wLeNdrRJEnb5W+oSlJD\nxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh\n4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQ\ncZekhoy7JDU0VNyTXE9yOcmlJPNrHL83yd8m+a8kvzD6MSVJW7FvC2uPV9WtdY49B/wc8NDOR5Ik\n7dRItmWq6mZVPQ58ZRTPJ0namWHjXsD5JAtJZsc5kCRp54bdljlWVYtJDgEXklytqotbfbHBF4ZZ\ngOnp6a1+uiRpSEO9c6+qxcHtTWAOOLqdF6uqM1U1U1UzU1NT23kKSdIQNo17kv1JDizfB04AV8Y9\nmCRp+4bZljkMzCVZXn+2qs4lOQVQVaeTfCMwD7wKeDnJu4HXV9XzY5pbkrSBTeNeVdeA+9Z4/PSK\n+/8K3D3a0SRJ2+VvqEpSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLu\nktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3\nSWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1NFTck1xPcjnJpSTzaxxPkt9L8lSSJ5LcP/pRJUnD2reF\ntcer6tY6xx4EXjf480bgA4NbSdIEjGpb5iTw4VryGeDrktw5oueWJG3RsHEv4HyShSSzaxy/C/jS\nio9vDB6TJE3AsNsyx6pqMckh4EKSq1V1ccXxrPE5tfqBwReGWYDp6ektDytJGs5Q79yranFwexOY\nA46uWnIDuGfFx3cDi2s8z5mqmqmqmampqe1NLEna1KZxT7I/yYHl+8AJ4MqqZY8Bbx/81Mx3A/9e\nVU+PfFpJ0lCG2ZY5DMwlWV5/tqrOJTkFUFWngU8DbwGeAv4D+PHxjCtJGsamca+qa8B9azx+esX9\nAh4Z7WiSpO3yN1QlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lq\nyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1\nZNwlqaFU1WReOHkW+OI2P/0gcGuE4+wFnvPtwXO+PezknL+5qqY2WzSxuO9Ekvmqmpn0HLvJc749\neM63h904Z7dlJKkh4y5JDe3VuJ+Z9AAT4DnfHjzn28PYz3lP7rlLkja2V9+5S5I2sOfinuT7kvxD\nkqeS/OKk59kNSa4nuZzkUpL5Sc8zDkk+mORmkisrHvv6JBeS/OPg9tWTnHHU1jnn9yb5l8G1vpTk\nLZOccZSS3JPkr5I8meRzSX5+8Hjb67zBOY/9Ou+pbZkkdwBfAL4XuAE8Drytqj4/0cHGLMl1YKaq\n2v4scJI3AS8CH66qbx889lvAc1X1G4Mv5K+uqkcnOecorXPO7wVerKrfnuRs45DkTuDOqvpskgPA\nAvAQ8E6aXucNzvmHGPN13mvv3I8CT1XVtar6b+AjwMkJz6QRqKqLwHOrHj4JfGhw/0Ms/aVoY51z\nbquqnq6qzw7uvwA8CdxF4+u8wTmP3V6L+13Al1Z8fINd+g81YQWcT7KQZHbSw+yiw1X1NCz9JQEO\nTXie3fIzSZ4YbNu02aJYKckR4DuBv+M2uc6rzhnGfJ33WtyzxmN7Z19p+45V1f3Ag8Ajg3/Oq6cP\nAK8FvgN4GvidyY4zekm+FvgY8O6qen7S8+yGNc557Nd5r8X9BnDPio/vBhYnNMuuqarFwe1NYI6l\n7anbwTODPcvlvcubE55n7Krqmap6qapeBn6fZtc6ydewFLk/rqqPDx5ufZ3XOufduM57Le6PA69L\n8pokrwR+BHhswjONVZL9g2/EkGQ/cAK4svFntfEY8I7B/XcAn5zgLLtiOXIDD9PoWicJ8IfAk1X1\nuysOtb3O653zblznPfXTMgCDHxl6H3AH8MGq+vUJjzRWSb6FpXfrAPuAsx3POcmfAG9m6f+W9wzw\nHuATwEeBaeCfgR+sqjbfgFznnN/M0j/VC7gO/NTyfvRel+QB4K+By8DLg4d/iaU96JbXeYNzfhtj\nvs57Lu6SpM3ttW0ZSdIQjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLU0P8C6hhFPFT/g/AA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d8afbf390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 100\n",
    "plt.plot(np.convolve(ef.history[:,'batches',:,'train_loss'][0], np.ones((N,))/N, mode='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = X[:10]\n",
    "pred = ef.predict(eval_data)\n",
    "pred_proba = ef.predict_proba(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vous', 'etes', 'tous', 'heureux', '.', 'EOS']\n",
      "['you', 'you', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['je', 'ne', 'suis', 'pas', 'suppose', 'boire', '.', 'EOS']\n",
      "['i', 'i', 'i', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['il', 'est', 'quelque', 'peu', 'timide', '.', 'EOS']\n",
      "['i', 'i', '.', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['il', 'y', 'travaille', '.', 'EOS']\n",
      "['i', 'i', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['je', 'ne', 'suis', 'dans', 'le', 'camp', 'de', 'personne', '.', 'EOS']\n",
      "['i', 'i', 'i', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['nous', 'sommes', 'tous', 'la', '.', 'EOS']\n",
      "['i', 'i', '.', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['ils', 's', 'amusent', '.', 'EOS']\n",
      "['i', 'i', '.', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['il', 'est', 'toujours', 'cloue', 'au', 'lit', '.', 'EOS']\n",
      "['i', 'i', '.', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['j', 'echoue', 'dans', 'mon', 'travail', '.', 'EOS']\n",
      "['i', 'i', 'i', '.', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS']\n",
      "\n",
      "['il', 'revasse', 'toujours', '.', 'EOS']\n",
      "['i', 'i', '.', '.', 'EOS', 'SOS', 'SOS', 'SOS', 'SOS', 'SOS']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (sent_in, sent_out) in zip(eval_data, pred):\n",
    "    print([input_lang.index2word.get(w[0], '???') for w in sent_in])\n",
    "    print([output_lang.index2word[w] for w in sent_out])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130, 130,   4,   4,   1,   0,   0,   0,   0,   0],\n",
       "       [  2,   2,   2,   4,   4,   1,   0,   0,   0,   0],\n",
       "       [  2,   2,   4,   4,   4,   1,   0,   0,   0,   0],\n",
       "       [  2,   2,   4,   4,   1,   0,   0,   0,   0,   0],\n",
       "       [  2,   2,   2,   4,   4,   1,   0,   0,   0,   0],\n",
       "       [  2,   2,   4,   4,   4,   1,   0,   0,   0,   0],\n",
       "       [  2,   2,   4,   4,   4,   1,   0,   0,   0,   0],\n",
       "       [  2,   2,   4,   4,   4,   1,   0,   0,   0,   0],\n",
       "       [  2,   2,   2,   4,   4,   4,   1,   0,   0,   0],\n",
       "       [  2,   2,   4,   4,   1,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
